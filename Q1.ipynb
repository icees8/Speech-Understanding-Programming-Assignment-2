{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmXfhxOItguX+/RltsMDSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icees8/Speech-Understanding-Programming-Assignment-2/blob/main/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio._internal import download_url_to_file\n",
        "from torchaudio.datasets.utils import _extract_zip, _load_waveform"
      ],
      "metadata": {
        "id": "6gIkpEup6nfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VoxCeleb Dataset from Torchaudio\n",
        "\n",
        "[Source](https://pytorch.org/audio/main/_modules/torchaudio/datasets/voxceleb1.html)"
      ],
      "metadata": {
        "id": "liz75DUT6quo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 16000\n",
        "_ARCHIVE_CONFIGS = {\n",
        "    \"dev\": {\n",
        "        \"archive_name\": \"vox1_dev_wav.zip\",\n",
        "        \"urls\": [\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partaa\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partab\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partac\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partad\",\n",
        "        ],\n",
        "        \"checksums\": [\n",
        "            \"21ec6ca843659ebc2fdbe04b530baa4f191ad4b0971912672d92c158f32226a0\",\n",
        "            \"311d21e0c8cbf33573a4fce6c80e5a279d80736274b381c394319fc557159a04\",\n",
        "            \"92b64465f2b2a3dc0e4196ae8dd6828cbe9ddd1f089419a11e4cbfe2e1750df0\",\n",
        "            \"00e6190c770b27f27d2a3dd26ee15596b17066b715ac111906861a7d09a211a5\",\n",
        "        ],\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"archive_name\": \"vox1_test_wav.zip\",\n",
        "        \"url\": \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\",\n",
        "        \"checksum\": \"8de57f347fe22b2c24526e9f444f689ecf5096fc2a92018cf420ff6b5b15eaea\",\n",
        "    },\n",
        "}\n",
        "_IDEN_SPLIT_URL = \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\"\n",
        "_VERI_TEST_URL = \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\"\n",
        "\n",
        "\n",
        "def _download_extract_wavs(root: str):\n",
        "    for archive in [\"dev\", \"test\"]:\n",
        "        archive_name = _ARCHIVE_CONFIGS[archive][\"archive_name\"]\n",
        "        archive_path = os.path.join(root, archive_name)\n",
        "        # The zip file of dev data is splited to 4 chunks.\n",
        "        # Download and combine them into one file before extraction.\n",
        "        if archive == \"dev\":\n",
        "            urls = _ARCHIVE_CONFIGS[archive][\"urls\"]\n",
        "            checksums = _ARCHIVE_CONFIGS[archive][\"checksums\"]\n",
        "            with open(archive_path, \"wb\") as f:\n",
        "                for url, checksum in zip(urls, checksums):\n",
        "                    file_path = os.path.join(root, os.path.basename(url))\n",
        "                    download_url_to_file(url, file_path, hash_prefix=checksum)\n",
        "                    with open(file_path, \"rb\") as f_split:\n",
        "                        f.write(f_split.read())\n",
        "        else:\n",
        "            url = _ARCHIVE_CONFIGS[archive][\"url\"]\n",
        "            checksum = _ARCHIVE_CONFIGS[archive][\"checksum\"]\n",
        "            download_url_to_file(url, archive_path, hash_prefix=checksum)\n",
        "        _extract_zip(archive_path)\n",
        "\n",
        "\n",
        "def _get_flist(root: str, file_path: str, subset: str) -> List[str]:\n",
        "    f_list = []\n",
        "    if subset == \"train\":\n",
        "        index = 1\n",
        "    elif subset == \"dev\":\n",
        "        index = 2\n",
        "    else:\n",
        "        index = 3\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            id, path = line.split()\n",
        "            if int(id) == index:\n",
        "                f_list.append(path)\n",
        "    return sorted(f_list)\n",
        "\n",
        "\n",
        "def _get_paired_flist(root: str, veri_test_path: str):\n",
        "    f_list = []\n",
        "    with open(veri_test_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            label, path1, path2 = line.split()\n",
        "            f_list.append((label, path1, path2))\n",
        "    return f_list\n",
        "\n",
        "\n",
        "def _get_file_id(file_path: str, _ext_audio: str):\n",
        "    speaker_id, youtube_id, utterance_id = file_path.split(\"/\")[-3:]\n",
        "    utterance_id = utterance_id.replace(_ext_audio, \"\")\n",
        "    file_id = \"-\".join([speaker_id, youtube_id, utterance_id])\n",
        "    return file_id\n",
        "\n",
        "\n",
        "class VoxCeleb1(Dataset):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "    \"\"\"\n",
        "\n",
        "    _ext_audio = \".wav\"\n",
        "\n",
        "    def __init__(self, root: Union[str, Path], download: bool = False) -> None:\n",
        "        # Get string representation of 'root' in case Path object is passed\n",
        "        root = os.fspath(root)\n",
        "        self._path = os.path.join(root, \"wav\")\n",
        "        if not os.path.isdir(self._path):\n",
        "            if not download:\n",
        "                raise RuntimeError(\n",
        "                    f\"Dataset not found at {self._path}. Please set `download=True` to download the dataset.\"\n",
        "                )\n",
        "            _download_extract_wavs(root)\n",
        "\n",
        "    def get_metadata(self, n: int):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, n: int):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "[docs]class VoxCeleb1Identification(VoxCeleb1):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset for speaker identification task.\n",
        "\n",
        "    Each data sample contains the waveform, sample rate, speaker id, and the file id.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        subset (str, optional): Subset of the dataset to use. Options: [\"train\", \"dev\", \"test\"]. (Default: ``\"train\"``)\n",
        "        meta_url (str, optional): The url of meta file that contains the list of subset labels and file paths.\n",
        "            The format of each row is ``subset file_path\". For example: ``1 id10006/nLEBBc9oIFs/00003.wav``.\n",
        "            ``1``, ``2``, ``3`` mean ``train``, ``dev``, and ``test`` subest, respectively.\n",
        "            (Default: ``\"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\"``)\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "\n",
        "    Note:\n",
        "        The file structure of `VoxCeleb1Identification` dataset is as follows:\n",
        "\n",
        "        └─ root/\n",
        "\n",
        "         └─ wav/\n",
        "\n",
        "         └─ speaker_id folders\n",
        "\n",
        "        Users who pre-downloaded the ``\"vox1_dev_wav.zip\"`` and ``\"vox1_test_wav.zip\"`` files need to move\n",
        "        the extracted files into the same ``root`` directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, root: Union[str, Path], subset: str = \"train\", meta_url: str = _IDEN_SPLIT_URL, download: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__(root, download)\n",
        "        if subset not in [\"train\", \"dev\", \"test\"]:\n",
        "            raise ValueError(\"`subset` must be one of ['train', 'dev', 'test']\")\n",
        "        # download the iden_split.txt to get the train, dev, test lists.\n",
        "        meta_list_path = os.path.join(root, os.path.basename(meta_url))\n",
        "        if not os.path.exists(meta_list_path):\n",
        "            download_url_to_file(meta_url, meta_list_path)\n",
        "        self._flist = _get_flist(self._path, meta_list_path, subset)\n",
        "\n",
        "[docs]    def get_metadata(self, n: int) -> Tuple[str, int, int, str]:\n",
        "        \"\"\"Get metadata for the n-th sample from the dataset. Returns filepath instead of waveform,\n",
        "        but otherwise returns the same fields as :py:func:`__getitem__`.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            str:\n",
        "                Path to audio\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Speaker ID\n",
        "            str:\n",
        "                File ID\n",
        "        \"\"\"\n",
        "        file_path = self._flist[n]\n",
        "        file_id = _get_file_id(file_path, self._ext_audio)\n",
        "        speaker_id = file_id.split(\"-\")[0]\n",
        "        speaker_id = int(speaker_id[3:])\n",
        "        return file_path, SAMPLE_RATE, speaker_id, file_id\n",
        "\n",
        "\n",
        "[docs]    def __getitem__(self, n: int) -> Tuple[Tensor, int, int, str]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            Tensor:\n",
        "                Waveform\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Speaker ID\n",
        "            str:\n",
        "                File ID\n",
        "        \"\"\"\n",
        "        metadata = self.get_metadata(n)\n",
        "        waveform = _load_waveform(self._path, metadata[0], metadata[1])\n",
        "        return (waveform,) + metadata[1:]\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._flist)\n",
        "\n",
        "\n",
        "\n",
        "[docs]class VoxCeleb1Verification(VoxCeleb1):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset for speaker verification task.\n",
        "\n",
        "    Each data sample contains a pair of waveforms, sample rate, the label indicating if they are\n",
        "    from the same speaker, and the file ids.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        meta_url (str, optional): The url of meta file that contains a list of utterance pairs\n",
        "            and the corresponding labels. The format of each row is ``label file_path1 file_path2\".\n",
        "            For example: ``1 id10270/x6uYqmx31kE/00001.wav id10270/8jEAjG6SegY/00008.wav``.\n",
        "            ``1`` means the two utterances are from the same speaker, ``0`` means not.\n",
        "            (Default: ``\"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\"``)\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "\n",
        "    Note:\n",
        "        The file structure of `VoxCeleb1Verification` dataset is as follows:\n",
        "\n",
        "        └─ root/\n",
        "\n",
        "         └─ wav/\n",
        "\n",
        "         └─ speaker_id folders\n",
        "\n",
        "        Users who pre-downloaded the ``\"vox1_dev_wav.zip\"`` and ``\"vox1_test_wav.zip\"`` files need to move\n",
        "        the extracted files into the same ``root`` directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root: Union[str, Path], meta_url: str = _VERI_TEST_URL, download: bool = False) -> None:\n",
        "        super().__init__(root, download)\n",
        "        # download the veri_test.txt to get the list of training pairs and labels.\n",
        "        meta_list_path = os.path.join(root, os.path.basename(meta_url))\n",
        "        if not os.path.exists(meta_list_path):\n",
        "            download_url_to_file(meta_url, meta_list_path)\n",
        "        self._flist = _get_paired_flist(self._path, meta_list_path)\n",
        "\n",
        "[docs]    def get_metadata(self, n: int) -> Tuple[str, str, int, int, str, str]:\n",
        "        \"\"\"Get metadata for the n-th sample from the dataset. Returns filepaths instead of waveforms,\n",
        "        but otherwise returns the same fields as :py:func:`__getitem__`.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            str:\n",
        "                Path to audio file of speaker 1\n",
        "            str:\n",
        "                Path to audio file of speaker 2\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Label\n",
        "            str:\n",
        "                File ID of speaker 1\n",
        "            str:\n",
        "                File ID of speaker 2\n",
        "        \"\"\"\n",
        "        label, file_path_spk1, file_path_spk2 = self._flist[n]\n",
        "        label = int(label)\n",
        "        file_id_spk1 = _get_file_id(file_path_spk1, self._ext_audio)\n",
        "        file_id_spk2 = _get_file_id(file_path_spk2, self._ext_audio)\n",
        "        return file_path_spk1, file_path_spk2, SAMPLE_RATE, label, file_id_spk1, file_id_spk2\n",
        "\n",
        "\n",
        "[docs]    def __getitem__(self, n: int) -> Tuple[Tensor, Tensor, int, int, str, str]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            Tensor:\n",
        "                Waveform of speaker 1\n",
        "            Tensor:\n",
        "                Waveform of speaker 2\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Label\n",
        "            str:\n",
        "                File ID of speaker 1\n",
        "            str:\n",
        "                File ID of speaker 2\n",
        "        \"\"\"\n",
        "        metadata = self.get_metadata(n)\n",
        "        waveform_spk1 = _load_waveform(self._path, metadata[0], metadata[2])\n",
        "        waveform_spk2 = _load_waveform(self._path, metadata[1], metadata[2])\n",
        "        return (waveform_spk1, waveform_spk2) + metadata[2:]\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._flist)\n"
      ],
      "metadata": {
        "id": "-4yQIZTsgrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load models\n"
      ],
      "metadata": {
        "id": "gvnrnRf17318"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ecapa tdnn"
      ],
      "metadata": {
        "id": "kgUUGTw-GXfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "from speechbrain.inference.speaker import EncoderClassifier"
      ],
      "metadata": {
        "id": "fJ06qNGJHB5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecapa = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":\"cuda\"})"
      ],
      "metadata": {
        "id": "Uyw6XbXtGczw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wavlm base plus"
      ],
      "metadata": {
        "id": "IFwc-QfjHNln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, WavLMForXVector"
      ],
      "metadata": {
        "id": "INUjPI36HSgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wavlm_base_plus_feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/wavlm-base-plus-sv\")\n",
        "wavlm_base_plus = WavLMForXVector.from_pretrained(\"microsoft/wavlm-base-plus-sv\")"
      ],
      "metadata": {
        "id": "uOiJXyVnHPq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wavlm large"
      ],
      "metadata": {
        "id": "_o0oToHeHawH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, WavLMForXVector"
      ],
      "metadata": {
        "id": "dkio4VP4HeGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wavlm_large_feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/wavlm-large\")\n",
        "wavlm_large = WavLMForXVector.from_pretrained(\"microsoft/wavlm-large\")"
      ],
      "metadata": {
        "id": "e-4QAMckHcf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equal error rate"
      ],
      "metadata": {
        "id": "KGPhXd8pImio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "def equal_error_rate(y_true, y_pred)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred, pos_label=1)\n",
        "    fnr = 1 - tpr\n",
        "\n",
        "    EER_p = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "    EER_n = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "\n",
        "    return np.mean([EER_p , EER_n])"
      ],
      "metadata": {
        "id": "FbqgDnMeIsD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}